{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# scikit-learn models and functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Logistic Regression Models\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SequentialFeatureSelector  # slow processing\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV']\n"
     ]
    }
   ],
   "source": [
    "# import training & final test data\n",
    "df_train = pd.read_csv('../data/processed/clean_train.csv')\n",
    "df_test = pd.read_csv('../data/processed/clean_test.csv')\n",
    "\n",
    "# Extract the column TARGET_5Yrs and save it into variable called target\n",
    "target = df_train.pop('TARGET_5Yrs')\n",
    "\n",
    "labels = df_train.columns.tolist() \n",
    "print(labels)\n",
    "\n",
    "# original list for reference\n",
    "# ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV']\n",
    "# ['GP', 'MIN', 'PTS', 'FGM', 'FGA', 'FG%', '3P Made', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV']\n",
    "\n",
    "# copy original data\n",
    "df_fix_train = df_train.copy()\n",
    "df_fix_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep selected features / cols\n",
    "def select_features(df_train, df_test, keep_cols=['']):\n",
    "    # take copies of the Cleaned data up to now - so we can rerun from here different feature selections\n",
    "    df_clean_new = df_train.copy()\n",
    "    df_clean_new_test = df_test.copy()\n",
    "    \n",
    "    return df_clean_new[keep_cols], df_clean_new_test[keep_cols]\n",
    "\n",
    "\n",
    "# ALL Features for baseline testing for training models\n",
    "# df_clean_R1, df_clean_R1_test = select_features(df_cleaned, df_clean_test, keep_cols=labels)\n",
    "# check still the same number of rows & columns as original cleaned training data\n",
    "# print('df_clean_R1 row,cols    ',df_clean_R1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>-8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>-3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>39.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>70.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>38.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>65.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>67.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7847</th>\n",
       "      <td>8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>38.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>10</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7671</th>\n",
       "      <td>10</td>\n",
       "      <td>14.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "5323  -8   5.8  1.5  0.6  1.9  33.6      0.0  0.2  13.9  0.1  0.2  63.6   0.0   \n",
       "7400  -3   6.1  2.1  0.8  1.9  39.1     -0.2 -0.5  19.2  0.6  0.9  70.2   0.6   \n",
       "6450   1   5.0  1.2  0.5  1.2  42.2      0.1  0.1  11.9  0.2  0.3  58.0   0.1   \n",
       "3093   3   8.3  2.0  0.8  2.2  35.0      0.2  0.8  18.6  0.4  0.9  38.9   0.4   \n",
       "2763   4   3.8  0.9  0.3  1.0  33.5      0.1  0.2  29.0  0.1  0.1  76.5   0.0   \n",
       "5008   6   5.7  1.2  0.5  1.3  41.5      0.3  1.3   8.0  0.1  0.1  65.6   0.0   \n",
       "4598   8   5.1  1.5  0.7  2.0  36.1      0.2  1.0  11.0  0.1  0.1  67.2   0.1   \n",
       "7847   8   6.4  1.5  0.5  1.5  38.8     -0.1 -0.1  20.2  0.3  0.5  68.5   0.2   \n",
       "7871  10   5.5  1.8  0.6  1.5  43.2      0.3  0.9  11.2  0.3  0.5  63.0   0.2   \n",
       "7671  10  14.8  4.0  1.5  3.7  40.5      0.6  1.7  31.6  0.6  0.9  66.0   0.6   \n",
       "\n",
       "      DREB  REB  AST  STL  BLK  TOV  \n",
       "5323   0.5  0.6  0.2  0.1 -0.5  0.3  \n",
       "7400   0.4  0.8  0.1  0.3  0.1  0.4  \n",
       "6450   0.3  0.4  0.4  0.3 -0.1  0.3  \n",
       "3093   0.9  1.4  0.5  0.3  0.2  0.3  \n",
       "2763   0.3  0.4  0.1  0.1  0.1  0.1  \n",
       "5008   0.4  0.5  0.3  0.1  0.1  0.3  \n",
       "4598   0.4  0.5  0.1  0.1 -0.1  0.2  \n",
       "7847   0.4  0.7  0.5  0.3 -0.1  0.3  \n",
       "7871   0.4  0.7  0.4  0.1 -0.1  0.4  \n",
       "7671   1.5  2.2  0.6  0.4  0.2  0.7  "
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['GP']<19].sort_values(['GP'], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - negative values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1629</td>\n",
       "      <td>1658</td>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP  MIN  PTS  FGM  FGA  FG%  3P Made   3PA  3P%  FTM  FTA  FT%  OREB  DREB  \\\n",
       "0   2    0    0    0    0    0     1629  1658  878    0    0    1     0     0   \n",
       "\n",
       "   REB  AST  STL   BLK  TOV  \n",
       "0    0    0    0  1048    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - negative values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>775</td>\n",
       "      <td>773</td>\n",
       "      <td>435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP  MIN  PTS  FGM  FGA  FG%  3P Made  3PA  3P%  FTM  FTA  FT%  OREB  DREB  \\\n",
       "0   0    0    0    0    0    0      775  773  435    0    0    0     0     0   \n",
       "\n",
       "   REB  AST  STL  BLK  TOV  \n",
       "0    0    0    0  456    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count negative values in each column\n",
    "df_neg = pd.DataFrame()\n",
    "for i in range(len(df_train.columns)):\n",
    "    df_neg[labels[i]] = [df_train[df_train[labels[i]]<0][labels[i]].count()]  \n",
    "    \n",
    "df_neg_test = pd.DataFrame()\n",
    "for i in range(len(df_test.columns)):\n",
    "    df_neg_test[labels[i]] = [df_test[df_test[labels[i]]<0][labels[i]].count()]  \n",
    "\n",
    "print('Training data - negative values')\n",
    "display(df_neg)\n",
    "\n",
    "print('Training data - negative values')\n",
    "display(df_neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg_val = df_neg.transpose()\n",
    "\n",
    "# plotting a bar chart negative values\n",
    "plt.bar(np.arange(len(labels)), neg_val[0], tick_label=labels) # , color = ['red', 'green'])\n",
    " \n",
    "# naming the x-axis\n",
    "plt.xlabel('x - axis')\n",
    "plt.xticks(rotation=45)\n",
    "# naming the y-axis\n",
    "plt.ylabel('y - axis')\n",
    "# plot title\n",
    "plt.title('Negative values')\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values - GP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>-8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>-3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>39.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>70.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GP  MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "5323  -8  5.8  1.5  0.6  1.9  33.6      0.0  0.2  13.9  0.1  0.2  63.6   0.0   \n",
       "7400  -3  6.1  2.1  0.8  1.9  39.1     -0.2 -0.5  19.2  0.6  0.9  70.2   0.6   \n",
       "\n",
       "      DREB  REB  AST  STL  BLK  TOV  \n",
       "5323   0.5  0.6  0.2  0.1 -0.5  0.3  \n",
       "7400   0.4  0.8  0.1  0.3  0.1  0.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check out negative GP\n",
    "print('Negative values - GP')\n",
    "display(df_fix_train[df_fix_train['GP']<=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values - BLK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53</td>\n",
       "      <td>12.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>44.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>63</td>\n",
       "      <td>19.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>49.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>44.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>68</td>\n",
       "      <td>14.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>50.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>37.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>47</td>\n",
       "      <td>10.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>70.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "4   58  12.3   4.7  1.6  4.0  40.0      0.5  1.7  38.7  1.1  1.3  76.9   0.2   \n",
       "7   53  12.1   4.7  1.8  4.1  44.1      0.1  0.2  25.7  0.9  1.0  80.2   0.6   \n",
       "30  63  19.5  10.7  4.5  9.2  49.1      0.8  2.2  44.4  1.1  1.3  83.0   0.3   \n",
       "81  68  14.8   6.8  2.7  5.2  50.9      0.4  0.9  37.3  1.2  1.5  84.0   0.8   \n",
       "83  47  10.9   4.5  1.8  3.9  43.5      0.5  1.5  36.5  0.9  1.3  70.4   0.5   \n",
       "\n",
       "    DREB  REB  AST  STL  BLK  TOV  \n",
       "4    0.6  0.9  1.5  0.5 -0.4  0.9  \n",
       "7    1.1  1.6  0.8  0.4 -0.2  0.6  \n",
       "30   1.1  1.4  3.4  1.0 -0.5  1.6  \n",
       "81   1.3  2.2  1.1  0.3 -0.3  0.9  \n",
       "83   0.7  1.3  0.8  0.5 -1.0  0.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BLK negative = 1048 rows\n",
    "print('Negative values - BLK')\n",
    "display(df_fix_test.loc[(df_fix_test['BLK']<0)][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values - 3P Made\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>16.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>46.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>69.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78</td>\n",
       "      <td>23.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>52.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>33.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>50.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>55.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>59</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>62.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "5   59  16.1   7.1  2.8   4.5  62.0     -0.1 -0.6   3.4  1.7  2.7  58.6   1.8   \n",
       "6   45   8.3   3.2  1.4   2.8  46.4     -0.5 -1.6   8.9  0.5  0.7  69.3   0.5   \n",
       "16  78  23.9   8.1  3.1   5.8  52.1     -0.1 -0.1  33.8  2.1  3.2  64.3   1.4   \n",
       "18  27   8.5   1.6  0.7   1.4  50.4     -0.2 -0.6  22.4  0.1  0.2  55.8   0.6   \n",
       "21  59  35.0  20.5  8.7  14.8  62.3     -0.5 -1.4   0.0  4.2  6.0  69.2   6.9   \n",
       "\n",
       "    DREB   REB  AST  STL  BLK  TOV  \n",
       "5    2.6   4.6  0.6  0.6  0.4  0.9  \n",
       "6    0.5   1.2  0.2  0.1  0.2  0.4  \n",
       "16   2.3   3.7  1.4  0.6  0.3  1.8  \n",
       "18   1.1   1.5  0.4  0.3  0.0  0.4  \n",
       "21   7.2  13.8  0.9  1.5  3.5  2.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3P Made negative = 1629 rows\n",
    "print('Negative values - 3P Made')\n",
    "display(df_fix_test.loc[(df_fix_test['3P Made']<0)][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data negative cols - mean\n",
      "GP 62.7949487371843\n",
      "3P Made 0.4482098982098982\n",
      "3PA 1.2396929108134596\n",
      "3P% 22.930386507378778\n",
      "FT% 71.3764095511939\n",
      "BLK 0.3967156166114006\n",
      "\n",
      "Test data negative cols - mean\n",
      "3P Made 0.4482098982098982\n",
      "3PA 1.2396929108134596\n",
      "3P% 22.930386507378778\n",
      "BLK 0.3967156166114006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate mean for cols with negative values - update those values with the mean\n",
    "df_fix_train = df_train.copy()\n",
    "df_fix_test = df_train.copy()\n",
    "\n",
    "def fix_negative_values(df_fix, df_neg_count, show=False, fix=False, title=''):\n",
    "    if title!='':\n",
    "        print(title)\n",
    "        \n",
    "    df_neg_fix = df_fix.copy()\n",
    "    for i in range(len(df_neg_count.columns)):\n",
    "        neg_val = int(df_neg_count.iloc[:,i].values)\n",
    "        if neg_val>0:\n",
    "            mean_val = df_neg_fix[labels[i]].loc[(df_neg_fix[labels[i]]>0)].mean()\n",
    "            if show==True:\n",
    "                print(labels[i],mean_val)\n",
    "\n",
    "            if fix==True:\n",
    "                # update negative values with the mean for that column\n",
    "                df_neg_fix[labels[i]].loc[(df_neg_fix[labels[i]]<0)]=mean_val\n",
    "                \n",
    "    return df_neg_fix\n",
    "    \n",
    "fix_negative_values(df_fix_train, df_neg, True, False, 'Training data negative cols - mean') \n",
    "print('')\n",
    "fix_negative_values(df_fix_test, df_neg_test, True, False, 'Test data negative cols - mean') \n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before fix 3PA: [-1.0, -0.5, -0.1, -0.6, -1.0, -0.2, -0.7, -0.5, -0.4, -0.1, -1.6, -0.6, -0.1, -0.7, -1.6, -1.1, -0.3, -0.6, -0.7, -0.4]\n",
      "before fix BLK: [-0.2, -0.2, -0.1, -0.1, -0.7, -0.1, -0.1, -0.2, -0.1, -1.7, -0.2, -0.7, -0.3, -0.2, -0.2, -0.5, -0.1, -0.1, -0.1, -0.1]\n",
      "\n",
      "after fix 3PA : Series([], Name: 3PA, dtype: float64)\n",
      "after fix BLK : Series([], Name: BLK, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "print('before fix 3PA:',list(df_fix_train['3PA'].loc[(df_fix_train['3PA']<0)])[0:20])\n",
    "print('before fix BLK:',list(df_fix_train['BLK'].loc[(df_fix_train['BLK']<0)])[0:20])\n",
    "\n",
    "# set negative values to the mean\n",
    "df_fix_train = fix_negative_values(df_fix_train, df_neg, False, True, '')  \n",
    "df_fix_test = fix_negative_values(df_fix_test, df_neg_test, False, True, '')  \n",
    "\n",
    "print('\\nafter fix 3PA :',df_fix_test['3PA'].loc[(df_fix_test['3PA']<0)])\n",
    "print('after fix BLK :',df_fix_test['BLK'].loc[(df_fix_test['BLK']<0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# set defaults\n",
    "random_state=100\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare training data for modelling - Standardising, Resampling for imbalanced data\n",
    "def Prep_Model_Data(df_clean, target, scaler='', resample='', random_state=8):\n",
    "    features_no = len(df_clean.columns)\n",
    "    \n",
    "    # rescale eg: scaler = StandardScaler()\n",
    "    if scaler!='':\n",
    "        df_clean = scaler.fit_transform(df_clean)\n",
    "        # df_clean_test = scaler.fit_transform(df_clean_test)\n",
    "\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # Split randomly the dataset with random_state=8 into 2 different sets: data (80%) and test (20%)\n",
    "    X_data, X_test, y_data, y_test = train_test_split(df_clean, target, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Split the remaining data (80%) randomly with random_state=8 into 2 different sets: training (80%) and validation (20%)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=random_state) \n",
    "    \n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # RESAMPLE if indicated\n",
    "    \n",
    "    # Original Training data\n",
    "    if resample=='NO RESAMPLE' or resample=='':\n",
    "        X_train_res, y_train_res = X_train, y_train\n",
    "        X_val_res, y_val_res =  X_val, y_val\n",
    "        X_test_res, y_test_res =  X_test, y_test\n",
    "        #print(resample,'NO Resample -',features_no,'Features')\n",
    "    \n",
    "    # SMOTE - treat Imbalanced Target data after splitting Training & Test & Validation data\n",
    "    if resample=='SMOTE':\n",
    "        X_train_res, y_train_res = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "        X_val_res, y_val_res = SMOTE(random_state=random_state).fit_resample(X_val, y_val)\n",
    "        X_test_res, y_test_res = SMOTE(random_state=random_state).fit_resample(X_test, y_test)\n",
    "        #print(resample,'Resample -',features_no,'Features')\n",
    "\n",
    "    # ADASYN - treat Imbalanced Target data after splitting Training & Test & Validation data\n",
    "    if resample=='ADASYN':\n",
    "        X_train_res, y_train_res = ADASYN(random_state=random_state).fit_resample(X_train, y_train)\n",
    "        X_val_res, y_val_res = ADASYN(random_state=random_state).fit_resample(X_val, y_val)\n",
    "        X_test_res, y_test_res = ADASYN(random_state=random_state).fit_resample(X_test, y_test)\n",
    "       \n",
    "    return X_train_res, y_train_res, X_val_res, y_val_res, X_test_res, y_test_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "def Train_Classifier(X_train_res, y_train_res, X_val_res, y_val_res, X_test_res, y_test_res, classifier, features='all', resample='resample'):\n",
    "    t_start = time.process_time()\n",
    "    # fit model\n",
    "    classify = classifier.fit(X_train_res, y_train_res)\n",
    "    t_end = time.process_time()       \n",
    "    t_diff = t_end - t_start\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Compare accuracy of the given test data\n",
    "    \n",
    "    # baseline target average\n",
    "    y_mode = y_train_res.mode()\n",
    "    \n",
    "    if resample=='NO RESAMPLE' or resample=='':\n",
    "        y_base_res = np.full((len(y_train_res), 1), y_mode)\n",
    "    else: \n",
    "        y_base_res = np.full((len(y_train_res), 1), y_mode[0])\n",
    "\n",
    "    # for debugging during dev/test\n",
    "    if 1==2:\n",
    "        print('mode',y_train_res.mode(), '\\ttype:',type(y_train_res.mode()))\n",
    "        print('len(X_train)',len(X_train_res))\n",
    "        print('len(y_train)',len(y_train_res))\n",
    "        print('y_base_res',y_base_res)\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    # final test (unseen) data AUC score\n",
    "    pred_prob = classifier.predict_proba(X_test_res)\n",
    "    auc_score = roc_auc_score(y_test_res, pred_prob[:,1])\n",
    "    \n",
    "    # simple print of accuracy scores\n",
    "    if 1==2:\n",
    "        print(f\"Compare accuracy between data sets - testing {features} features \")\n",
    "        print(f\"Classifier - {classify}\")\n",
    "        print(f\"Imbalanced data fix - {resample}\")\n",
    "        print(\"Baseline:     \",accuracy_score(y_train_res, y_base_res))\n",
    "        print(\"Train data:   \",classifier.score(X_train_res, y_train_res))\n",
    "        print(\"Validation:   \",classifier.score(X_val_res, y_val_res))\n",
    "        print('Test data auc:',auc_score,'\\n')    \n",
    "    \n",
    "    clf_str = f'{classify}'\n",
    "    clf_n = clf_str.find('(')\n",
    "    \n",
    "    df_scores = []\n",
    "    df_scores.append((clf_str[0:clf_n], 'None' if resample=='' else resample, X_train_res.ndim,\n",
    "                 accuracy_score(y_train_res, y_base_res), \n",
    "                 classifier.score(X_train_res, y_train_res),\n",
    "                 classifier.score(X_val_res, y_val_res),\n",
    "                 roc_auc_score(y_test_res, pred_prob[:,1]) ))\n",
    "    \n",
    "    return classify, X_train_res, y_train_res, X_val_res, y_val_res, X_test_res, y_test_res, df_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# MLPClassifier parameters\n",
    "activation='logistic'\n",
    "solver='adam'     # sgd, adam (default)\n",
    "alpha=0.01        # 0.0001 default\n",
    "max_iter=300\n",
    "batch_size=100    \n",
    "\n",
    "random_state=100\n",
    "\n",
    "# Classification Models defined - MLPClassifier()\n",
    "clf_NN_MLP=MLPClassifier(activation=activation, solver=solver, alpha=alpha, batch_size=batch_size, random_state=random_state)\n",
    "\n",
    "# Classification Models defined - LogisticRegression()\n",
    "clf_LR=LogisticRegression(C=109.85411419875572, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100, n_jobs=None, penalty='l2',\n",
    "          tol=0.0001, verbose=0, warm_start=False, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/5-feature-selection-method-from-scikit-learn-you-should-know-ed4d116e4172\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "t_start = time.process_time()\n",
    "\n",
    "# Selecting the Best important features according to Logistic Regression\n",
    "sfs_selector = SequentialFeatureSelector(estimator=LogisticRegression(), n_features_to_select=3, cv=5, direction ='backward')\n",
    "sfs_selector.fit(df_fix_train, target)\n",
    "\n",
    "print(sfs_selector)\n",
    "\n",
    "top_feat_sfs = df_fix_train.columns[sfs_selector.get_support()]\n",
    "print(top_feat_sfs)\n",
    "print('Time taken:', (time.process_time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectFromModel(estimator=LogisticRegression(), max_features=3)\n",
      "Index(['PTS', 'FGA', 'OREB'], dtype='object')\n",
      "Time taken: 0.8314798589999555\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature Selection via SelectFromModel\n",
    "# https://towardsdatascience.com/5-feature-selection-method-from-scikit-learn-you-should-know-ed4d116e4172\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "t_start = time.process_time()\n",
    "\n",
    "# Selecting the Best important features according to Logistic Regression using SelectFromModel\n",
    "sfm_selector = SelectFromModel(estimator=LogisticRegression(), max_features=3)\n",
    "sfm_selector.fit(df_fix_train, target)\n",
    "\n",
    "print(sfm_selector)\n",
    "\n",
    "top_feat_sfm = df_fix_train.columns[sfm_selector.get_support()]\n",
    "print(top_feat_sfm)\n",
    "print('Time taken:', (time.process_time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LogisticRegression(), n_features_to_select=6)\n",
      "Index(['FGM', 'FGA', 'FTM', 'OREB', 'DREB', 'REB'], dtype='object')\n",
      "Time taken: 8.99\n"
     ]
    }
   ],
   "source": [
    "# 3. Recursive Feature Elimination (RFE)\n",
    "# https://towardsdatascience.com/5-feature-selection-method-from-scikit-learn-you-should-know-ed4d116e4172\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "t_start = time.process_time()\n",
    "\n",
    "# Selecting the Best important features according to Logistic Regression\n",
    "rfe_selector = RFE(estimator=LogisticRegression(),n_features_to_select=6, step=1)\n",
    "rfe_selector.fit(df_fix_train, target)\n",
    "\n",
    "print(rfe_selector)\n",
    "\n",
    "top_feat_rfe = df_fix_train.columns[rfe_selector.get_support()]\n",
    "print(top_feat_rfe)\n",
    "\n",
    "print('Time taken:', round((time.process_time()-t_start),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature_select = {\n",
    "    'Select From Model': SelectFromModel(estimator=LogisticRegression(), max_features=max_features)\n",
    "    'Recursive Feature Elimination': RFE(estimator=LogisticRegression(),n_features_to_select=max_features, step=1)\n",
    "    'Sequential Feature Select Back': SequentialFeatureSelector(estimator=LogisticRegression(), n_features_to_select=3, cv=5, direction ='backward')\n",
    "    'Sequential Feature Select Fwd': SequentialFeatureSelector(estimator=LogisticRegression(), n_features_to_select=3, cv=5, direction ='forward')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=random_state),\n",
    "    \"Neural Net\": MLPClassifier(alpha = 1,random_state=random_state)\n",
    "}\n",
    "\n",
    "dict_scaler = {\n",
    "    'Standard': StandardScaler(),\n",
    "    'Normalizer': Normalizer(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "dict_resample = {\n",
    "    'None'  : '',\n",
    "    'SMOTE' : 'SMOTE',\n",
    "    'ADASYN': 'ADASYN'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector  # slow processing\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def select_features_auto_batch(X_train, y_train, no_select_feat=2, estimator=None, max_features=3, step=1, cv=5, direction='forward'):\n",
    "    t_start = time.process_time()\n",
    "    print('Feature Selection different techniques')\n",
    "    \n",
    "    dict_top_fs = {}\n",
    "    for feat_select_name, feature_selector in list(dict_feature_select.items())[:no_select_feat]:\n",
    "\n",
    "        # Selecting the Best important features according to Logistic Regression\n",
    "        # fs_selector = SequentialFeatureSelector(estimator=LogisticRegression(), n_features_to_select=max_features, cv=cv, direction=direction)\n",
    "        fs_selector = feature_selector\n",
    "        fs_selector.fit(X_train, y_train)\n",
    "\n",
    "        #print(fs_selector)\n",
    "\n",
    "        top_feat_fs = X_train.columns[fs_selector.get_support()]\n",
    "        # print(top_feat_fs,'\\n')\n",
    "        \n",
    "        dict_top_fs[feat_select_name] = {'feature_selector': fs_selector, \n",
    "                                         'top_features'    : top_feat_fs\n",
    "                                        }\n",
    "        \n",
    "    print('Time taken:', round((time.process_time()-t_start),2),'seconds')\n",
    "    return dict_top_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_auto(X_train, y_train, feature_selector, no_select_feat=2, estimator=None, max_features=3, step=1, cv=5, direction='forward'):\n",
    "    t_start = time.process_time()\n",
    "    print(f'Feature Selection - {feature_selector} - {max_features}')\n",
    "    \n",
    "    # define here to parameters are dynamic\n",
    "    dict_feature_select = {\n",
    "        'SFM': SelectFromModel(estimator=estimator, max_features=max_features),\n",
    "        'RFE': RFE(estimator=estimator,n_features_to_select=max_features, step=step),\n",
    "        'SFSB': SequentialFeatureSelector(estimator=estimator, n_features_to_select=3, cv=5, direction ='backward'),\n",
    "        'SFSF': SequentialFeatureSelector(estimator=estimator, n_features_to_select=3, cv=5, direction ='forward')\n",
    "    }  \n",
    "    \n",
    "    # Selecting the Best important features according to Logistic Regression\n",
    "    # fs_selector = SequentialFeatureSelector(estimator=LogisticRegression(), n_features_to_select=max_features, cv=cv, direction=direction)\n",
    "    fs_selector = dict_feature_select.get(feature_selector)\n",
    "    fs_selector.fit(X_train, y_train)\n",
    "    print('fs_selector',fs_selector)\n",
    "\n",
    "    top_feat_fs = X_train.columns[fs_selector.get_support()]\n",
    "    # print(top_feat_fs,'\\n')\n",
    "        \n",
    "    #print('Time taken:', round((time.process_time()-t_start),2),'seconds')\n",
    "    return top_feat_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection - RFE - 3\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=3)\n",
      "Feature Selection - RFE - 3\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=3)\n",
      "Feature Selection - RFE - 3\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=3)\n",
      "Feature Selection - RFE - 3\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=3)\n",
      "Time taken: 42.63 seconds\n",
      "Feature Selection - RFE - 6\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=6)\n",
      "Feature Selection - RFE - 6\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=6)\n",
      "Feature Selection - RFE - 6\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=6)\n",
      "Feature Selection - RFE - 6\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=6)\n",
      "Time taken: 86.91 seconds\n",
      "Feature Selection - RFE - 9\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=9)\n",
      "Feature Selection - RFE - 9\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=9)\n",
      "Feature Selection - RFE - 9\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=9)\n",
      "Feature Selection - RFE - 9\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=9)\n",
      "Time taken: 128.81 seconds\n",
      "Feature Selection - RFE - 12\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=12)\n",
      "Feature Selection - RFE - 12\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=12)\n",
      "Feature Selection - RFE - 12\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=12)\n",
      "Feature Selection - RFE - 12\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=12)\n",
      "Time taken: 169.84 seconds\n",
      "Feature Selection - RFE - 15\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=15)\n",
      "Feature Selection - RFE - 15\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=15)\n",
      "Feature Selection - RFE - 15\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=15)\n",
      "Feature Selection - RFE - 15\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=15)\n",
      "Time taken: 210.65 seconds\n",
      "Feature Selection - RFE - 37\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=37)\n",
      "Feature Selection - RFE - 37\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=37)\n",
      "Feature Selection - RFE - 37\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=37)\n",
      "Feature Selection - RFE - 37\n",
      "fs_selector RFE(estimator=AdaBoostClassifier(random_state=100), n_features_to_select=37)\n",
      "Time taken: 251.74 seconds\n"
     ]
    }
   ],
   "source": [
    "sort_by='auc_score'\n",
    "show_results=False\n",
    "verbose=False\n",
    "resample=''\n",
    "step=3\n",
    "rerun_no=1\n",
    "scaler_no=len(dict_scaler)\n",
    "resample_no=len(dict_resample)\n",
    "no_classifiers = 3  #len(dict_classifiers)\n",
    "estimater = dict_classifiers.get('AdaBoost')\n",
    "\n",
    "t_start = time.process_time()\n",
    "\n",
    "# step through number of features to include\n",
    "for i in range(3, len(df_fix_train.columns), step):\n",
    "    \n",
    "    # increment by 'step' unless it's just before the total # of columns\n",
    "    i+=0 if i<(len(df_fix_train.columns)-1) else i+1\n",
    "    # print(len(df_fix_train.columns[0:i]))\n",
    "    \n",
    "    # auto select features based on 'step' iteration\n",
    "    top_feat = select_features_auto(df_fix_train, target, feature_selector='RFE', no_select_feat=2, estimator=estimater, max_features=i, step=1, cv=5, direction='forward')\n",
    "    # print(top_feat)\n",
    "    \n",
    "    # def batch_stand_norm_data(df_fix_train, df_fix_test, target, top_feat, no_classifiers=4, scaler_no=3, resample_no=3, random_state=random_state, show_results=True, verbose=True):\n",
    "    df_best = batch_stand_norm_data(df_fix_train, df_fix_test, target, top_feat, no_classifiers, scaler_no, resample_no, random_state, show_results, verbose)\n",
    "\n",
    "    # show top 3 model results\n",
    "    #display(df_best.sort_values(by=sort_by, ascending=False)[0:3])\n",
    "\n",
    "    print('Time taken:', round((time.process_time()-t_start),2),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_no</th>\n",
       "      <th>classifier</th>\n",
       "      <th>features</th>\n",
       "      <th>resample</th>\n",
       "      <th>transform</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test 1-3</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>19.0</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.753059</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.749540</td>\n",
       "      <td>0.838263</td>\n",
       "      <td>0.874504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test 3-3</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>19.0</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.759151</td>\n",
       "      <td>0.744087</td>\n",
       "      <td>0.745404</td>\n",
       "      <td>0.833288</td>\n",
       "      <td>0.817834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test 1-2</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.771101</td>\n",
       "      <td>0.772523</td>\n",
       "      <td>0.758019</td>\n",
       "      <td>0.830344</td>\n",
       "      <td>0.902597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test 3-2</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.770751</td>\n",
       "      <td>0.775901</td>\n",
       "      <td>0.741038</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>0.874498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test 4-2</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.754150</td>\n",
       "      <td>0.748874</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.815910</td>\n",
       "      <td>0.921459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test 4-3</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>19.0</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.741320</td>\n",
       "      <td>0.731538</td>\n",
       "      <td>0.723169</td>\n",
       "      <td>0.814241</td>\n",
       "      <td>0.871978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test 4-1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>19.0</td>\n",
       "      <td>None</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.837891</td>\n",
       "      <td>0.833750</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.682393</td>\n",
       "      <td>0.427498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test 3-1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>19.0</td>\n",
       "      <td>None</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.836523</td>\n",
       "      <td>0.830625</td>\n",
       "      <td>0.826562</td>\n",
       "      <td>0.682247</td>\n",
       "      <td>0.418065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test 1-1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>19.0</td>\n",
       "      <td>None</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.837891</td>\n",
       "      <td>0.833750</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.681943</td>\n",
       "      <td>0.378065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test 4-2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>0.663315</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.627358</td>\n",
       "      <td>0.680614</td>\n",
       "      <td>0.865553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_no           classifier  features resample         transform  \\\n",
       "2  Test 1-3             AdaBoost      19.0   ADASYN  StandardScaler()   \n",
       "2  Test 3-3             AdaBoost      19.0   ADASYN    MinMaxScaler()   \n",
       "2  Test 1-2             AdaBoost      19.0    SMOTE  StandardScaler()   \n",
       "2  Test 3-2             AdaBoost      19.0    SMOTE    MinMaxScaler()   \n",
       "2  Test 4-2             AdaBoost      19.0    SMOTE    RobustScaler()   \n",
       "2  Test 4-3             AdaBoost      19.0   ADASYN    RobustScaler()   \n",
       "0  Test 4-1  Logistic Regression      19.0     None    RobustScaler()   \n",
       "0  Test 3-1  Logistic Regression      19.0     None    MinMaxScaler()   \n",
       "0  Test 1-1  Logistic Regression      19.0     None  StandardScaler()   \n",
       "0  Test 4-2  Logistic Regression      19.0    SMOTE    RobustScaler()   \n",
       "\n",
       "   train_score  val_score  test_score  auc_score  train_time  \n",
       "2     0.753059   0.743066    0.749540   0.838263    0.874504  \n",
       "2     0.759151   0.744087    0.745404   0.833288    0.817834  \n",
       "2     0.771101   0.772523    0.758019   0.830344    0.902597  \n",
       "2     0.770751   0.775901    0.741038   0.819588    0.874498  \n",
       "2     0.754150   0.748874    0.740566   0.815910    0.921459  \n",
       "2     0.741320   0.731538    0.723169   0.814241    0.871978  \n",
       "0     0.837891   0.833750    0.828125   0.682393    0.427498  \n",
       "0     0.836523   0.830625    0.826562   0.682247    0.418065  \n",
       "0     0.837891   0.833750    0.828125   0.681943    0.378065  \n",
       "0     0.663315   0.668919    0.627358   0.680614    0.865553  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best.sort_values(by=sort_by, ascending=False)[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection different techniques\n",
      "\n",
      "Time taken: 6.89 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Select From Model': {'feature_selector': SelectFromModel(estimator=LogisticRegression(), max_features=6),\n",
       "  'top_features': Index(['PTS', 'FGM', 'FGA', 'OREB', 'BLK', 'TOV'], dtype='object')},\n",
       " 'Recursive Feature Elimination': {'feature_selector': RFE(estimator=LogisticRegression(), n_features_to_select=6),\n",
       "  'top_features': Index(['FGM', 'FGA', 'FTM', 'FTA', 'OREB', 'AST'], dtype='object')}}"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_no=1\n",
    "cv_no=5\n",
    "max_features=6\n",
    "direction='forward'\n",
    "estimator=LogisticRegression()\n",
    "no_select_feat=len(dict_feature_select)\n",
    "scaler=StandardScaler()\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = Prep_Model_Data(df_fix_train, target, scaler='', resample='', random_state=random_state)\n",
    "\n",
    "dict_top_feat = select_features_auto(X_train, y_train, no_select_feat, estimator, max_features, step_no, cv_no, direction='forward')\n",
    "dict_top_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_classify(X_train, Y_train, X_test, Y_test, X_val, Y_val, X_final, no_classifiers = 4, \n",
    "                   test_no=1, sample_no=1, scaler=scaler, resample='', verbose = True):\n",
    "    \"\"\"\n",
    "    This method, takes as input the X, Y matrices of the Train and Test set.\n",
    "    And fits them on all of the Classifiers specified in the dict_classifier.\n",
    "    The trained models, and accuracies are saved in a dictionary. The reason to use a dictionary\n",
    "    is because it is very easy to save the whole dictionary with the pickle module.\n",
    "    \n",
    "    Usually, the SVM, Random Forest and Gradient Boosting Classifier take quiet some time to train. \n",
    "    So it is best to train them on a smaller dataset first and \n",
    "    decide whether you want to comment them out or not based on the test accuracy score.\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_models = {}\n",
    "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
    "        t_start = time.process_time()\n",
    "        # fit model\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        t_end = time.process_time()       \n",
    "        t_diff = t_end - t_start\n",
    "        \n",
    "        #--------------------------------------------------------------------------\n",
    "        # Save the fitted model into the folder 'models', named for each classifier\n",
    "        # dump(classifier,  '../models/r{d}_{c}.joblib'.format(d=rerun_no, c=classifier_name))\n",
    "        #--------------------------------------------------------------------------\n",
    "\n",
    "        # Save the predictions from this model for the training and validation sets, and the final \"test\" set \n",
    "        y_train_preds = classifier.predict(X_train)\n",
    "        y_val_preds = classifier.predict(X_val)\n",
    "        \n",
    "        #save the final \"test\" prediction probabilities for Kaggle\n",
    "        y_final_preds = classifier.predict_proba(X_final)\n",
    "         \n",
    "        # combine final \"test\" Id column with prediction probabilities column (cover to dataframe first) \n",
    "        frames = [df_test.iloc[:,0], pd.DataFrame(y_final_preds[:,1])]\n",
    "        result = pd.concat(frames, axis=1) \n",
    "        result.columns = ['Id','tmp']\n",
    "        result['TARGET_5Yrs'] = [round(num, 2) for num in result['tmp']]\n",
    "        result.drop(['tmp'], axis=1, inplace=True)\n",
    "        \n",
    "        #--------------------------------------------------------------------------\n",
    "        # Save the final predictions for submission to Kaggle\n",
    "        result.to_csv('../data/processed/group1_r{d}_{c}.csv'.format(d=test_no, c=classifier_name), index=False)\n",
    "        #--------------------------------------------------------------------------\n",
    "\n",
    "        # baseline target average\n",
    "        y_mode = Y_train.mode()\n",
    "\n",
    "        if resample=='NO RESAMPLE' or resample=='':\n",
    "            y_base = np.full((len(Y_train), 1), y_mode)\n",
    "        else: \n",
    "            y_base = np.full((len(Y_train), 1), y_mode[0])\n",
    "\n",
    "        # classifier scores - training, test & validation data\n",
    "        baseline = accuracy_score(Y_train, y_base)\n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        val_score = classifier.score(X_val, Y_val)\n",
    "        test_score = classifier.score(X_test, Y_test)\n",
    "         \n",
    "        # predict probabilities\n",
    "        pred_prob = classifier.predict_proba(X_test) \n",
    "        # auc scores\n",
    "        auc_score = roc_auc_score(Y_test, pred_prob[:,1])\n",
    "        \n",
    "        dict_models[classifier_name] = {'model'      : classifier,         'test_num'    : f'Test {test_no}-{sample_no}',  \n",
    "                                        'transform'  : scaler,             'resample'    : 'None' if resample=='' else resample, \n",
    "                                        'features'   : np.size(X_train,1), 'train_score' : train_score, \n",
    "                                        'val_score'  : val_score,          'test_score'  : test_score,    \n",
    "                                        'auc_score'  : auc_score,          'train_time'  : t_diff }\n",
    "        if verbose:\n",
    "            print(\"trained {s}, {r}, {c} - in {f:.2f} s\\tauc: {a:.3f}\".format(c=classifier_name, r='None' if resample=='' else resample, s=scaler, f=t_diff,a=auc_score))\n",
    "            print('')\n",
    "           \n",
    "    return dict_models\n",
    "\n",
    "def display_dict_models(dict_models, Y_test, sort_by='auc_score', show_results=False):\n",
    "    cls = [key for key in dict_models.keys()]\n",
    "    test_num = [dict_models[key]['test_num'] for key in cls]\n",
    "    features = [dict_models[key]['features'] for key in cls]\n",
    "    resample = [dict_models[key]['resample'] for key in cls]\n",
    "    scaler = [dict_models[key]['transform'] for key in cls]\n",
    "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
    "    val_s = [dict_models[key]['val_score'] for key in cls]\n",
    "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
    "    roc_auc = [dict_models[key]['auc_score'] for key in cls]\n",
    "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
    "    \n",
    "    # setup output dataframe\n",
    "    columns = ['test_no','classifier','features','resample','transform','train_score','val_score','test_score','auc_score','train_time']\n",
    "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls),len(columns))), columns = columns)\n",
    "    \n",
    "    df_scores = []\n",
    "    best_test, best_clf, best_auc, best_feat, best_resample, best_transform = None, None, float(\"inf\"), None, None, None\n",
    "        \n",
    "    for ii in range(0,len(cls)):\n",
    "        df_.loc[ii, 'classifier'] = cls[ii]\n",
    "        df_.loc[ii, 'test_no'] = test_num[ii]\n",
    "        df_.loc[ii, 'features'] = features[ii]\n",
    "        df_.loc[ii, 'resample'] = resample[ii]\n",
    "        df_.loc[ii, 'transform'] = scaler[ii]\n",
    "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
    "        df_.loc[ii, 'val_score'] = val_s[ii]\n",
    "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
    "        df_.loc[ii, 'auc_score'] = roc_auc[ii]\n",
    "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
    "    \n",
    "    df_scores = df_.sort_values(by='test_no', ascending=False)\n",
    "\n",
    "    if show_results:\n",
    "        print('\\n')\n",
    "        # print(df_.sort_values(by=sort_by, ascending=False)[0:1])\n",
    "        display(df_.sort_values(by=sort_by, ascending=False))\n",
    "        \n",
    "    return df_scores\n",
    "\n",
    "\n",
    "def batch_stand_norm_data(df_fix_train, df_fix_test, target, top_feat, no_classifiers=4, scaler_no=3, resample_no=3, random_state=random_state, show_results=True, verbose=True):\n",
    "    # loop counters - test (scaler), resample\n",
    "    sample_no=0\n",
    "    \n",
    "    # best scores definition: best_auc, best_mape, best_pred, best_year = float(\"inf\"), float(\"inf\"), None, None\n",
    "    best_test, best_clf, best_auc, best_feat, best_resample, best_transform = None, None, float(\"inf\"), None, None, None\n",
    "    \n",
    "    # final test summary cols\n",
    "    # test_sum_cols = ['test_no','classifier','features','resample','transform','auc_score']\n",
    "    test_sum_cols = ['test_no','classifier','features','resample','transform','train_score','val_score','test_score','auc_score','train_time']\n",
    "    \n",
    "    df_overall = pd.DataFrame(columns = test_sum_cols)\n",
    "\n",
    "    # iterate through - dict_scaler\n",
    "    for resample_name, resample in list(dict_resample.items())[:resample_no]:\n",
    "        sample_no+=1   # increment each loop\n",
    "        test_no=0      # reset each loop\n",
    "        results = pd.DataFrame(columns = test_sum_cols)\n",
    "        \n",
    "        # autopick top 'i' features\n",
    "        top_feat = select_features_auto(df_fix_train, target, feature_selector='RFE', no_select_feat=2, estimator=estimater, max_features=i, step=1, cv=5, direction='forward')\n",
    "        \n",
    "        # intiailse training data for this test\n",
    "        df_clean_mod, df_clean_mod_test = select_features(df_fix_train, df_fix_test, top_feat)\n",
    "\n",
    "        # iterate through - dict_scaler\n",
    "        for scaler_name, scaler in list(dict_scaler.items())[:scaler_no]:\n",
    "            test_no+=1\n",
    "            \n",
    "            # Prepare Train/Val/Test data\n",
    "            X_train, y_train, X_val, y_val, X_test, y_test = Prep_Model_Data(df_clean_mod, target, scaler=scaler, resample=resample, random_state=random_state)\n",
    "\n",
    "            # run multiple classfication models\n",
    "            dict_models = batch_classify(X_train, y_train, X_val, y_val, X_test, y_test, df_clean_mod_test, no_classifiers, test_no, sample_no, scaler, resample, verbose)\n",
    "\n",
    "            # display performance results - accuracy scores\n",
    "            df_scores = display_dict_models(dict_models, y_test, sort_by, False)\n",
    "            \n",
    "            # convert scores to a DataFrame\n",
    "            # df_scores = pd.DataFrame(scores, columns=test_sum_cols)\n",
    "            # df_scores_best = df_scores.sort_values(by=sort_by, ascending=False)[0:1] \n",
    "            results = results.append(df_scores)\n",
    "    \n",
    "        # only keep best overall result for the Business Unit\n",
    "        # results_sort = results.sort_values(by=['auc_score'])[0:1]\n",
    "        df_overall = df_overall.append(results)\n",
    "    \n",
    "    return df_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained StandardScaler(), None, Logistic Regression - in 0.16 s\tauc: 0.657\n",
      "trained StandardScaler(), None, Neural Net - in 11.32 s\tauc: 0.648\n",
      "trained StandardScaler(), None, Naive Bayes - in 0.02 s\tauc: 0.624\n",
      "trained StandardScaler(), None, AdaBoost - in 0.44 s\tauc: 0.627\n",
      "\n",
      "trained Normalizer(), None, Logistic Regression - in 0.12 s\tauc: 0.647\n",
      "trained Normalizer(), None, Neural Net - in 11.01 s\tauc: 0.628\n",
      "trained Normalizer(), None, Naive Bayes - in 0.02 s\tauc: 0.647\n",
      "trained Normalizer(), None, AdaBoost - in 0.51 s\tauc: 0.614\n",
      "\n",
      "trained MinMaxScaler(), None, Logistic Regression - in 0.14 s\tauc: 0.646\n",
      "trained MinMaxScaler(), None, Neural Net - in 7.72 s\tauc: 0.641\n",
      "trained MinMaxScaler(), None, Naive Bayes - in 0.02 s\tauc: 0.624\n",
      "trained MinMaxScaler(), None, AdaBoost - in 0.40 s\tauc: 0.627\n",
      "\n",
      "trained StandardScaler(), SMOTE, Logistic Regression - in 0.15 s\tauc: 0.646\n",
      "trained StandardScaler(), SMOTE, Neural Net - in 15.47 s\tauc: 0.646\n",
      "trained StandardScaler(), SMOTE, Naive Bayes - in 0.03 s\tauc: 0.626\n",
      "trained StandardScaler(), SMOTE, AdaBoost - in 0.49 s\tauc: 0.694\n",
      "\n",
      "trained Normalizer(), SMOTE, Logistic Regression - in 0.20 s\tauc: 0.637\n",
      "trained Normalizer(), SMOTE, Neural Net - in 9.90 s\tauc: 0.620\n",
      "trained Normalizer(), SMOTE, Naive Bayes - in 0.03 s\tauc: 0.629\n",
      "trained Normalizer(), SMOTE, AdaBoost - in 0.51 s\tauc: 0.606\n",
      "\n",
      "trained MinMaxScaler(), SMOTE, Logistic Regression - in 0.28 s\tauc: 0.643\n",
      "trained MinMaxScaler(), SMOTE, Neural Net - in 9.25 s\tauc: 0.641\n",
      "trained MinMaxScaler(), SMOTE, Naive Bayes - in 0.02 s\tauc: 0.627\n",
      "trained MinMaxScaler(), SMOTE, AdaBoost - in 0.47 s\tauc: 0.701\n",
      "\n",
      "trained StandardScaler(), ADASYN, Logistic Regression - in 0.14 s\tauc: 0.642\n",
      "trained StandardScaler(), ADASYN, Neural Net - in 14.63 s\tauc: 0.636\n",
      "trained StandardScaler(), ADASYN, Naive Bayes - in 0.03 s\tauc: 0.618\n",
      "trained StandardScaler(), ADASYN, AdaBoost - in 0.32 s\tauc: 0.728\n",
      "\n",
      "trained Normalizer(), ADASYN, Logistic Regression - in 0.28 s\tauc: 0.633\n",
      "trained Normalizer(), ADASYN, Neural Net - in 8.84 s\tauc: 0.614\n",
      "trained Normalizer(), ADASYN, Naive Bayes - in 0.03 s\tauc: 0.625\n",
      "trained Normalizer(), ADASYN, AdaBoost - in 0.46 s\tauc: 0.595\n",
      "\n",
      "trained MinMaxScaler(), ADASYN, Logistic Regression - in 0.23 s\tauc: 0.637\n",
      "trained MinMaxScaler(), ADASYN, Neural Net - in 10.74 s\tauc: 0.633\n",
      "trained MinMaxScaler(), ADASYN, Naive Bayes - in 0.03 s\tauc: 0.619\n",
      "trained MinMaxScaler(), ADASYN, AdaBoost - in 0.47 s\tauc: 0.714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#====================================================================================================\n",
    "# MODEL TESTING RUN 2 - ALL FEATURES IN ORIGINAL DATA - SMOTE RESAMPLING IMBALANCED DATA\n",
    "#====================================================================================================\n",
    "sort_by='auc_score'\n",
    "show_results=False\n",
    "resample=''\n",
    "rerun_no=1\n",
    "scaler_no=len(dict_scaler)\n",
    "resample_no=len(dict_resample)\n",
    "no_classifiers = len(dict_classifiers)\n",
    "\n",
    "df_best = batch_stand_norm_data(df_fix_train, df_fix_test, target, top_feat, no_classifiers, scaler_no, resample_no, random_state, show_results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_no</th>\n",
       "      <th>classifier</th>\n",
       "      <th>features</th>\n",
       "      <th>resample</th>\n",
       "      <th>transform</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test 1-3</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>0.680104</td>\n",
       "      <td>0.663894</td>\n",
       "      <td>0.663284</td>\n",
       "      <td>0.727789</td>\n",
       "      <td>0.315686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test 3-3</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.663549</td>\n",
       "      <td>0.647988</td>\n",
       "      <td>0.648225</td>\n",
       "      <td>0.713838</td>\n",
       "      <td>0.465038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test 3-2</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>0.669394</td>\n",
       "      <td>0.643393</td>\n",
       "      <td>0.642925</td>\n",
       "      <td>0.701387</td>\n",
       "      <td>0.474180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_no classifier  features resample         transform  train_score  \\\n",
       "3  Test 1-3   AdaBoost       6.0   ADASYN  StandardScaler()     0.680104   \n",
       "3  Test 3-3   AdaBoost       6.0   ADASYN    MinMaxScaler()     0.663549   \n",
       "3  Test 3-2   AdaBoost       6.0    SMOTE    MinMaxScaler()     0.669394   \n",
       "\n",
       "   val_score  test_score  auc_score  train_time  \n",
       "3   0.663894    0.663284   0.727789    0.315686  \n",
       "3   0.647988    0.648225   0.713838    0.465038  \n",
       "3   0.643393    0.642925   0.701387    0.474180  "
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what models have the best AUC scores\n",
    "df_best.sort_values(by=sort_by, ascending=False)[0:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
